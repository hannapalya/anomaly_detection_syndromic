{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hannapalya/anomaly_detection_syndromic/blob/main/IF_LSTM_ensemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EegYWK48ByNI",
    "outputId": "88d271ae-3b52-4328-b25e-819831714e5d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "--- Signal 4 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.881, spec=0.972, thr=0.633695\n",
      "  IF@win14 → val sens=0.904, spec=0.979, thr=0.109523\n",
      "  Selected: IF (win=14), thr≈0.109523, val sens=0.904, val spec=0.979\n",
      "  TEST → Sens=0.871, Spec=0.980, POD=1.000, Tim=0.105\n",
      "\n",
      "--- Signal 5 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.665, spec=0.970, thr=0.027969\n",
      "  IF@win14 → val sens=0.630, spec=0.970, thr=0.015706\n",
      "  Selected: LSTM-AE (win=14), thr≈0.027969, val sens=0.665, val spec=0.970\n",
      "  TEST → Sens=0.643, Spec=0.973, POD=0.900, Tim=0.176\n",
      "\n",
      "--- Signal 6 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.497, spec=0.977, thr=0.292464\n",
      "  IF@win14 → val sens=0.474, spec=0.970, thr=0.023712\n",
      "  Selected: LSTM-AE (win=14), thr≈0.292464, val sens=0.497, val spec=0.977\n",
      "  TEST → Sens=0.424, Spec=0.979, POD=0.500, Tim=0.545\n",
      "\n",
      "--- Signal 7 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.885, spec=0.970, thr=0.087127\n",
      "  IF@win14 → val sens=0.889, spec=0.971, thr=0.107152\n",
      "  Selected: IF (win=14), thr≈0.107152, val sens=0.889, val spec=0.971\n",
      "  TEST → Sens=0.879, Spec=0.971, POD=1.000, Tim=0.042\n",
      "\n",
      "--- Signal 8 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.377, spec=0.970, thr=0.092633\n",
      "  IF@win14 → val sens=0.312, spec=0.971, thr=0.007860\n",
      "  Selected: LSTM-AE (win=14), thr≈0.092633, val sens=0.377, val spec=0.970\n",
      "  TEST → Sens=0.358, Spec=0.971, POD=0.550, Tim=0.568\n",
      "\n",
      "--- Signal 9 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.857, spec=0.973, thr=0.228742\n",
      "  IF@win14 → val sens=0.809, spec=0.973, thr=0.046630\n",
      "  Selected: LSTM-AE (win=14), thr≈0.228742, val sens=0.857, val spec=0.973\n",
      "  TEST → Sens=0.837, Spec=0.967, POD=1.000, Tim=0.132\n",
      "\n",
      "--- Signal 10 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.803, spec=0.974, thr=0.045964\n",
      "  IF@win14 → val sens=0.391, spec=0.970, thr=0.006011\n",
      "  Selected: LSTM-AE (win=14), thr≈0.045964, val sens=0.803, val spec=0.974\n",
      "  TEST → Sens=0.770, Spec=0.973, POD=1.000, Tim=0.138\n",
      "\n",
      "--- Signal 11 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.368, spec=0.970, thr=0.789764\n",
      "  IF@win21 → val sens=0.487, spec=0.970, thr=0.029123\n",
      "  Selected: IF (win=21), thr≈0.029123, val sens=0.487, val spec=0.970\n",
      "  TEST → Sens=0.533, Spec=0.980, POD=0.950, Tim=0.312\n",
      "\n",
      "--- Signal 12 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.852, spec=0.970, thr=0.025410\n",
      "  IF@win21 → val sens=0.852, spec=0.971, thr=0.138168\n",
      "  Selected: IF (win=21), thr≈0.138168, val sens=0.852, val spec=0.971\n",
      "  TEST → Sens=0.869, Spec=0.972, POD=1.000, Tim=0.038\n",
      "\n",
      "--- Signal 13 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.830, spec=0.971, thr=0.557175\n",
      "  IF@win7 → val sens=0.517, spec=0.970, thr=0.180210\n",
      "  Selected: LSTM-AE (win=14), thr≈0.557175, val sens=0.830, val spec=0.971\n",
      "  TEST → Sens=0.816, Spec=0.969, POD=1.000, Tim=0.064\n",
      "\n",
      "--- Signal 14 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.956, spec=0.971, thr=0.333705\n",
      "  IF@win7 → val sens=0.952, spec=0.976, thr=0.037234\n",
      "  Selected: LSTM-AE (win=14), thr≈0.333705, val sens=0.956, val spec=0.971\n",
      "  TEST → Sens=0.939, Spec=0.973, POD=1.000, Tim=0.047\n",
      "\n",
      "--- Signal 15 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.437, spec=0.972, thr=0.151254\n",
      "  IF@win14 → val sens=0.292, spec=0.970, thr=0.001451\n",
      "  Selected: LSTM-AE (win=14), thr≈0.151254, val sens=0.437, val spec=0.972\n",
      "  TEST → Sens=0.509, Spec=0.966, POD=0.850, Tim=0.450\n",
      "\n",
      "--- Signal 16 (Ensemble: LSTM vs IF) ---\n",
      "  Using 60 train sims, 20 val, 20 test\n",
      "  LSTM-AE@win14 → val sens=0.765, spec=0.971, thr=0.030340\n",
      "  IF@win14 → val sens=0.795, spec=0.973, thr=0.032765\n",
      "  Selected: IF (win=14), thr≈0.032765, val sens=0.795, val spec=0.973\n",
      "  TEST → Sens=0.756, Spec=0.976, POD=1.000, Tim=0.098\n",
      "\n",
      "=== ENSEMBLE SUMMARY (per-signal chosen model) ===\n",
      "      model  window       thr  val_sens  val_spec  sensitivity  specificity  \\\n",
      "4        IF      14  0.109523  0.903670  0.979317     0.870813     0.979815   \n",
      "5   LSTM-AE      14  0.027969  0.664596  0.970373     0.642651     0.973293   \n",
      "6   LSTM-AE      14  0.292464  0.497076  0.977290     0.424419     0.979154   \n",
      "7        IF      14  0.107152  0.888525  0.971406     0.878689     0.970612   \n",
      "8   LSTM-AE      14  0.092633  0.376623  0.970482     0.358407     0.971290   \n",
      "9   LSTM-AE      14  0.228742  0.856522  0.973312     0.837004     0.967205   \n",
      "10  LSTM-AE      14  0.045964  0.802768  0.974331     0.769759     0.973054   \n",
      "11       IF      21  0.029123  0.486842  0.970355     0.532895     0.979708   \n",
      "12       IF      21  0.138168  0.851759  0.971462     0.868852     0.972153   \n",
      "13  LSTM-AE      14  0.557175  0.829787  0.971456     0.816327     0.969314   \n",
      "14  LSTM-AE      14  0.333705  0.955823  0.971343     0.938697     0.973024   \n",
      "15  LSTM-AE      14  0.151254  0.436620  0.972451     0.509363     0.966051   \n",
      "16       IF      14  0.032765  0.795148  0.973350     0.755952     0.975575   \n",
      "\n",
      "     pod  timeliness  \n",
      "4   1.00    0.105245  \n",
      "5   0.90    0.175989  \n",
      "6   0.50    0.544985  \n",
      "7   1.00    0.041982  \n",
      "8   0.55    0.568111  \n",
      "9   1.00    0.132198  \n",
      "10  1.00    0.138359  \n",
      "11  0.95    0.312500  \n",
      "12  1.00    0.038240  \n",
      "13  1.00    0.063657  \n",
      "14  1.00    0.047303  \n",
      "15  0.85    0.449723  \n",
      "16  1.00    0.098148  \n",
      "\n",
      "Means:\n",
      " sensitivity    0.707987\n",
      "specificity    0.973096\n",
      "pod            0.903846\n",
      "timeliness     0.208957\n",
      "dtype: float64\n",
      "Saved: Ensemble_LSTM_IF_results.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Ensemble (per-signal chooser) of two attached adapters:\n",
    "- LSTM autoencoder: LSTM_AE_curr.py -> fit_and_score(...)\n",
    "- Isolation Forest: IsolationForest_tuned.py -> fit_and_score(...)\n",
    "\n",
    "Selection logic:\n",
    "  1) For each candidate, tune a threshold on validation scores to achieve >= SPEC_TARGET specificity.\n",
    "  2) Among candidates that meet the spec floor, choose the one with the HIGHEST SENSITIVITY.\n",
    "     Tie-breakers: higher specificity, then higher F_beta.\n",
    "  3) If none meet SPEC_TARGET, pick the one whose specificity is closest to SPEC_TARGET (higher better),\n",
    "     then highest sensitivity.\n",
    "\n",
    "Robust per-sim stitching: if a candidate returns per-sim test score lengths that differ from the\n",
    "constructed label lengths, we truncate to the common length and log a WARN (no crash).\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, numpy as np, pandas as pd\n",
    "from typing import Any, Dict, List, Tuple\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ===== USER CONFIG =====\n",
    "DATA_DIR      = \"/content\"     # <- set your data folder\n",
    "SIGNALS       = list(range(4, 17))\n",
    "DAYS_PER_YEAR = 364\n",
    "TRAIN_YEARS   = 6\n",
    "TRAIN_DAYS    = TRAIN_YEARS * DAYS_PER_YEAR\n",
    "VALID_DAYS    = 49 * 7\n",
    "RNG_STATE     = 42\n",
    "\n",
    "# Selection constraints / scoring\n",
    "SPEC_TARGET = 0.97     # tail specificity floor on validation\n",
    "SENS_FLOOR  = 0.00     # (optional) hard floor for sensitivity; keep 0 to purely prioritize sens after spec\n",
    "BETA        = 0.5      # tie-break metric (beta<1 favors specificity)\n",
    "\n",
    "# ===== SAFE IMPORT of ADAPTERS =====\n",
    "# ===== IMPORT YOUR MODELS (ADAPTERS) =====\n",
    "import importlib.util, importlib, sys, pathlib\n",
    "\n",
    "def import_adapter(path_str: str, func_name: str, module_name: str):\n",
    "    p = pathlib.Path(path_str)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Adapter not found at: {p}\")\n",
    "    # Always drop any cached module with the same alias\n",
    "    if module_name in sys.modules:\n",
    "        del sys.modules[module_name]\n",
    "    spec = importlib.util.spec_from_file_location(module_name, str(p))\n",
    "    mod = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(mod)  # executes the file (fresh)\n",
    "    if not hasattr(mod, func_name):\n",
    "        raise AttributeError(f\"{p.name} is missing `{func_name}()`\")\n",
    "    return getattr(mod, func_name)\n",
    "\n",
    "# Use stable, unique aliases to prevent TF/IF re-register issues\n",
    "lstm_fit_and_score = import_adapter(\"LSTM_AE_curr.py\", \"fit_and_score\", module_name=\"adapter_lstm\")\n",
    "iso_fit_and_score  = import_adapter(\"IsolationForest_tuned.py\", \"fit_and_score\", module_name=\"adapter_if\")\n",
    "from r_comparator_metrics import (\n",
    "    compute_sensitivity_R, compute_specificity_R, compute_fpr_R,\n",
    "    compute_pod_R, compute_timeliness_R, IDX_RANGE\n",
    ")\n",
    "\n",
    "\n",
    "# ===== HELPERS =====\n",
    "def load_data(sig: int):\n",
    "    X = pd.read_csv(os.path.join(DATA_DIR, f\"simulated_totals_sig{sig}.csv\"))\n",
    "    Y = (pd.read_csv(os.path.join(DATA_DIR, f\"simulated_outbreaks_sig{sig}.csv\")) > 0).astype(int)\n",
    "    date_col = next((c for c in [\"date\",\"Date\",\"ds\",\"timestamp\"] if c in X.columns), None)\n",
    "    if date_col:\n",
    "        X = X.drop(columns=[date_col])\n",
    "        if date_col in Y.columns: Y = Y.drop(columns=[date_col])\n",
    "    return X, Y\n",
    "\n",
    "def cross_sim_split(sims: List[dict], rng: np.random.RandomState, train_frac=0.6):\n",
    "    rng.shuffle(sims)\n",
    "    n_train = int(len(sims) * train_frac)\n",
    "    return sims[:n_train], sims[n_train:]\n",
    "\n",
    "def sens_spec(y_true: np.ndarray, y_pred: np.ndarray) -> Tuple[float,float]:\n",
    "    TN, FP, FN, TP = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
    "    sens = TP/(TP+FN) if (TP+FN)>0 else 0.0\n",
    "    spec = TN/(TN+FP) if (TN+FP)>0 else 0.0\n",
    "    return sens, spec\n",
    "\n",
    "def f_beta(s: float, sp: float, beta=BETA) -> float:\n",
    "    b2 = beta*beta\n",
    "    denom = (b2*s + sp)\n",
    "    return 0.0 if denom <= 0 else (1+b2)*s*sp / (denom + 1e-12)\n",
    "\n",
    "def tune_threshold(scores: np.ndarray, val_sims: list, val_lengths: list,\n",
    "                   spec_target=SPEC_TARGET, sens_floor=SENS_FLOOR, p_max=20.0) -> float:\n",
    "    \"\"\"\n",
    "    Given anomaly scores (higher = more anomalous), choose a percentile-based threshold\n",
    "    over the NEGATIVES' score distribution to meet specificity.\n",
    "    \"\"\"\n",
    "    # Build O_full for R-comparator metrics\n",
    "    O_full_val = np.stack([d[\"y\"] for d in val_sims], axis=1)\n",
    "    IDX_RANGE = np.arange(2205, 2548, dtype=int)\n",
    "    \n",
    "    if len(scores) == 0:  # degenerate; no alarms\n",
    "        return float(\"inf\")\n",
    "    # neg_mask no longer needed with R-comparator metrics\n",
    "    base = scores[neg_mask] if neg_mask.any() else scores\n",
    "    grid = np.linspace(0.5, p_max, num=200)  # 0.5%..20% tail\n",
    "    best_t = None\n",
    "    best_tuple = None  # (prioritized key)\n",
    "\n",
    "    # Primary: meet spec target, then maximize sensitivity\n",
    "    for p in grid:\n",
    "        thr = np.percentile(base, 100 - p)\n",
    "        yhat = (scores >= thr).astype(int)\n",
    "        # Build alarm matrix A from yhat predictions (split by simulation lengths)\n",
    "        A_list = []\n",
    "        offset = 0\n",
    "        for L in val_lengths:\n",
    "            if L > 0 and offset < len(yhat):\n",
    "                A_list.append(yhat[offset:offset+L])\n",
    "                offset += L\n",
    "        \n",
    "        if A_list and len(A_list) == len(val_sims):\n",
    "            max_len = max(len(a) for a in A_list)\n",
    "            A_padded = [np.pad(a, (0, max_len - len(a)), mode='constant') if len(a) < max_len else a for a in A_list]\n",
    "            A = np.column_stack(A_padded)\n",
    "            s = compute_sensitivity_R(A, O_full_val)\n",
    "            sp = compute_specificity_R(A, O_full_val, IDX_RANGE)\n",
    "        else:\n",
    "            s, sp = 0.0, 0.0\n",
    "        if sp >= spec_target:\n",
    "            key = (s, sp, f_beta(s, sp, BETA))  # prioritize sens, then spec, then F_beta\n",
    "            if (best_tuple is None) or (key > best_tuple):\n",
    "                best_tuple = key\n",
    "                best_t = float(thr)\n",
    "\n",
    "    # Fallback: if none meet spec target, pick closest spec to target (higher better), then sens\n",
    "    if best_t is None:\n",
    "        best_gap = 1e9\n",
    "        best_s   = -1.0\n",
    "        best_sp  = -1.0\n",
    "        for p in grid:\n",
    "            thr = np.percentile(base, 100 - p)\n",
    "            yhat = (scores >= thr).astype(int)\n",
    "            # Build alarm matrix A from yhat predictions (split by simulation lengths)\n",
    "        A_list = []\n",
    "        offset = 0\n",
    "        for L in val_lengths:\n",
    "            if L > 0 and offset < len(yhat):\n",
    "                A_list.append(yhat[offset:offset+L])\n",
    "                offset += L\n",
    "        \n",
    "        if A_list and len(A_list) == len(val_sims):\n",
    "            max_len = max(len(a) for a in A_list)\n",
    "            A_padded = [np.pad(a, (0, max_len - len(a)), mode='constant') if len(a) < max_len else a for a in A_list]\n",
    "            A = np.column_stack(A_padded)\n",
    "            s = compute_sensitivity_R(A, O_full_val)\n",
    "            sp = compute_specificity_R(A, O_full_val, IDX_RANGE)\n",
    "        else:\n",
    "            s, sp = 0.0, 0.0\n",
    "            gap = abs(sp - spec_target)\n",
    "            # prefer higher spec if gaps tie, then higher sens\n",
    "            if (gap < best_gap) or (gap == best_gap and (sp > best_sp or (sp == best_sp and s > best_s))):\n",
    "                best_t, best_gap, best_sp, best_s = float(thr), gap, sp, s\n",
    "\n",
    "    return best_t\n",
    "\n",
    "\n",
    "# ===== MAIN =====\n",
    "np.random.seed(RNG_STATE)\n",
    "rng = np.random.RandomState(RNG_STATE)\n",
    "\n",
    "summary = {}\n",
    "\n",
    "for S in SIGNALS:\n",
    "    print(f\"\\n--- Signal {S} (Ensemble: LSTM vs IF) ---\")\n",
    "    Xsig, Ysig = load_data(S)\n",
    "\n",
    "    # Build sim dicts\n",
    "    sims: List[dict] = []\n",
    "    for sim_idx, col in enumerate(Xsig.columns):\n",
    "        x = Xsig[col].to_numpy(np.float32, copy=False)\n",
    "        y = Ysig[col].to_numpy(np.int32, copy=False)\n",
    "        if len(x) >= TRAIN_DAYS + VALID_DAYS:\n",
    "            sims.append(dict(sim=f\"sig{S}_sim{sim_idx}\", x=x, y=y))\n",
    "    if not sims:\n",
    "        print(\"  No complete sims; skip.\")\n",
    "        continue\n",
    "\n",
    "    train_sims, held_sims = cross_sim_split(sims, rng, train_frac=0.6)\n",
    "    mid = max(1, len(held_sims)//2)\n",
    "    val_sims  = held_sims[:mid]\n",
    "    test_sims = held_sims[mid:] if len(held_sims) > 1 else held_sims\n",
    "    print(f\"  Using {len(train_sims)} train sims, {len(val_sims)} val, {len(test_sims)} test\")\n",
    "\n",
    "    # === get candidates from adapters ===\n",
    "    cand_results: List[Dict[str,Any]] = []\n",
    "    cand_results.append(lstm_fit_and_score(S, train_sims, val_sims, test_sims, rng_state=RNG_STATE))\n",
    "    cand_results.append(iso_fit_and_score(S,  train_sims, val_sims, test_sims, rng_state=RNG_STATE))\n",
    "\n",
    "    # === tune thresholds on validation & pick model ===\n",
    "    best = None\n",
    "    best_key = None  # tuple for prioritization\n",
    "\n",
    "    for res in cand_results:\n",
    "        yv = res[\"val_labels\"].astype(np.int32)\n",
    "        sv = res[\"val_scores\"].astype(np.float32)\n",
    "\n",
    "        \n",
    "        # NOTE: val_lengths must be computed from adapter results\n",
    "\n",
    "        # Build val_lengths for R-comparator metrics\n",
    "        val_lengths = [len(sv)] if len(sv) > 0 else [0]  # Simplified - may need adjustment\n",
    "thr = tune_threshold(sv, val_sims, val_lengths, SPEC_TARGET, SENS_FLOOR)\n",
    "        yhat = (sv >= thr).astype(int)\n",
    "        s, sp = sens_spec(yv, yhat)\n",
    "\n",
    "        # primary decision key: (meets_spec, sensitivity, specificity, F_beta)\n",
    "        meets = (sp >= SPEC_TARGET)\n",
    "        key = (1 if meets else 0, s, sp, f_beta(s, sp, BETA))\n",
    "\n",
    "        res.update(thr=float(thr), val_sens=float(s), val_spec=float(sp), decision_key=key)\n",
    "        print(f\"  {res['name']}@win{res['window']} → val sens={s:.3f}, spec={sp:.3f}, thr={thr:.6f}\")\n",
    "\n",
    "        if (best_key is None) or (key > best_key):\n",
    "            best, best_key = res, key\n",
    "\n",
    "    print(f\"  Selected: {best['name']} (win={best['window']}), thr≈{best['thr']:.6f}, \"\n",
    "          f\"val sens={best['val_sens']:.3f}, val spec={best['val_spec']:.3f}\")\n",
    "\n",
    "    # === test on tail ===\n",
    "    # Build per-sim labels using the selected window\n",
    "    test_labels_splits: List[np.ndarray] = []\n",
    "    for d in test_sims:\n",
    "        y_tail = d[\"y\"][-VALID_DAYS:]\n",
    "        y_al   = y_tail[best[\"window\"]-1:]\n",
    "        test_labels_splits.append(y_al.astype(np.int32))\n",
    "\n",
    "    # Sanity: number of sims must match\n",
    "    assert len(best[\"test_scores_splits\"]) == len(test_labels_splits), \\\n",
    "        \"Adapter must return test_scores_splits aligned to test_sims.\"\n",
    "\n",
    "    # Robust stacking with truncation if lengths drift\n",
    "    preds_cols, labels_cols = [], []\n",
    "    for idx, (scores, ycol) in enumerate(zip(best[\"test_scores_splits\"], test_labels_splits)):\n",
    "        if len(scores) != len(ycol):\n",
    "            L = min(len(scores), len(ycol))\n",
    "            print(f\"  WARN: sim#{idx} length mismatch (scores={len(scores)}, labels={len(ycol)}); truncating to {L}.\")\n",
    "            scores = scores[:L]; ycol = ycol[:L]\n",
    "        if len(scores) == 0:\n",
    "            # keep empty column — will be ignored when stacking if all are empty\n",
    "            preds_cols.append(np.zeros((0,), dtype=int))\n",
    "            labels_cols.append(ycol[:0])\n",
    "            continue\n",
    "        preds_cols.append((scores >= best[\"thr\"]).astype(int))\n",
    "        labels_cols.append(ycol)\n",
    "\n",
    "    if all(len(c) == 0 for c in preds_cols):\n",
    "        print(\"  No test windows; skipping metrics.\")\n",
    "        continue\n",
    "\n",
    "    # Equalize lengths across sims by trimming to min length (conservative, avoids ragged arrays)\n",
    "    min_len = min(len(c) for c in preds_cols if len(c) > 0)\n",
    "    preds_cols = [c[:min_len] for c in preds_cols if len(c) > 0]\n",
    "    labels_cols = [c[:min_len] for c in labels_cols if len(c) > 0]\n",
    "\n",
    "    A = np.stack(preds_cols, axis=1)   # [T, J]\n",
    "    O = np.stack(labels_cols, axis=1)  # [T, J]\n",
    "\n",
    "    sens = metric_sensitivity(A, O)\n",
    "    spec = metric_specificity(A, O)\n",
    "    pod  = metric_pod(A, O)\n",
    "    tim  = metric_timeliness(A, O)\n",
    "    print(f\"  TEST → Sens={sens:.3f}, Spec={spec:.3f}, POD={pod:.3f}, Tim={tim:.3f}\")\n",
    "\n",
    "    summary[S] = dict(\n",
    "        model=best[\"name\"], window=int(best[\"window\"]), thr=float(best[\"thr\"]),\n",
    "        val_sens=float(best[\"val_sens\"]), val_spec=float(best[\"val_spec\"]),\n",
    "        sensitivity=float(sens), specificity=float(spec), pod=float(pod), timeliness=float(tim)\n",
    "    )\n",
    "\n",
    "# ===== SUMMARY =====\n",
    "if summary:\n",
    "    df = pd.DataFrame.from_dict(summary, orient=\"index\")\n",
    "    print(\"\\n=== ENSEMBLE SUMMARY (per-signal chosen model) ===\")\n",
    "    print(df)\n",
    "    print(\"\\nMeans:\\n\", df[[\"sensitivity\",\"specificity\",\"pod\",\"timeliness\"]].mean(numeric_only=True))\n",
    "    df.to_csv(\"Ensemble_LSTM_IF_results.csv\")\n",
    "    print(\"Saved: Ensemble_LSTM_IF_results.csv\")\n",
    "else:\n",
    "    print(\"\\nNo results to summarize.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": [],
   "authorship_tag": "ABX9TyPpCiv27pvoB+VF1hXBUglo",
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}